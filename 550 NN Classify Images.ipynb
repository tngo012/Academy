{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classifying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set that color chanel value will be first\n",
    "K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image information\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and target from MINST data\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training image data into features\n",
    "data_train = data_train.reshape(data_train.shape[0], channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape test image data into features \n",
    "data_test = data_test.reshape(data_test.shape[0], channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale pixel intensity to between 0 and 1 \n",
    "features_train = data_train / 255 \n",
    "features_test = data_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode target \n",
    "target_train = np_utils.to_categorical(target_train) \n",
    "target_test = np_utils.to_categorical(target_test) \n",
    "number_of_classes = target_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start neural network \n",
    "network = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation function \n",
    "network.add(Conv2D(filters=64, kernel_size=(5, 5),  input_shape=(channels, width, height), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tai\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add max pooling layer with a 2x2 window \n",
    "network.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout layer \n",
    "network.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layer to flatten input \n",
    "network.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer of 128 units with a ReLU activation function \n",
    "network.add(Dense(128, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout layer \n",
    "network.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer with a softmax activation function \n",
    "network.add(Dense(number_of_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss=\"categorical_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tai\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 46s 770us/step - loss: 0.5920 - accuracy: 0.8173 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 45s 749us/step - loss: 0.1925 - accuracy: 0.9433 - val_loss: 0.0913 - val_accuracy: 0.9725\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 45s 755us/step - loss: 0.1254 - accuracy: 0.9629 - val_loss: 0.0623 - val_accuracy: 0.9798\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 45s 746us/step - loss: 0.0983 - accuracy: 0.9708 - val_loss: 0.0508 - val_accuracy: 0.9843\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 45s 746us/step - loss: 0.0813 - accuracy: 0.9755 - val_loss: 0.0418 - val_accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 45s 750us/step - loss: 0.0697 - accuracy: 0.9795 - val_loss: 0.0388 - val_accuracy: 0.9870\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 45s 748us/step - loss: 0.0615 - accuracy: 0.9814 - val_loss: 0.0366 - val_accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 45s 752us/step - loss: 0.0576 - accuracy: 0.9829 - val_loss: 0.0335 - val_accuracy: 0.9889\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 45s 746us/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.0336 - val_accuracy: 0.9884\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 45s 750us/step - loss: 0.0498 - accuracy: 0.9843 - val_loss: 0.0307 - val_accuracy: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19eff415588>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train neural network \n",
    "network.fit(features_train, # Features\n",
    "            target_train, # Target\n",
    "            epochs=10, # Number of epochs \n",
    "            batch_size=1000, # Number of observations per batch \n",
    "            validation_data=(features_test, target_test)) # Data for evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
